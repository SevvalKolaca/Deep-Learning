{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yGo0U6a_ByA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c42978a-99fb-499a-bc4c-d4ac347cf6b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!unzip \"/content/test.zip\"\\n!unzip \"/content/train.zip\"\\n!unzip \"/content/val.zip\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "!unzip \"/content/test.zip\"\n",
        "!unzip \"/content/train.zip\"\n",
        "!unzip \"/content/val.zip\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Activation, add, AveragePooling2D, Flatten, Dense\n",
        "from keras.backend import sigmoid\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.nn import AvgPool2d, Linear, Flatten, Sigmoid\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "GQ6c4Ab_CNqB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PYTORCH CNN"
      ],
      "metadata": {
        "id": "yR6_yIiqj-3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Swish(x):\n",
        "  return x * torch.sigmoid(x)\n",
        "\n",
        "class CNN(nn.Module): # derin ogrenme modeli\n",
        "  def __init__(self, number_of_classes = 9):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    # Layer 1 --> Convolutional Layer 1\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 2 --> Convolutional Layer 2\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 3 --> Convolutional Layer 3\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 4 --> Convolutional Layer 4\n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 5 --> Convolutional Layer 5\n",
        "    self.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 6 --> Convolutional Layer 6\n",
        "    self.conv6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 7 --> Convolutional Layer 7\n",
        "    self.conv7 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 8 --> Convolutional Layer 8\n",
        "    self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 9 --> Convolutional Layer 9\n",
        "    self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Layer 10 --> Pooling Layer\n",
        "    self.average_pooling = AvgPool2d(2)\n",
        "\n",
        "    # Layer 11 --> Flatten Layer\n",
        "    self.flatten = Flatten()\n",
        "\n",
        "    # Layer 12 --> Fully Connected Layer 1\n",
        "    self.fully_connected1 = Linear(in_features = (512 * 7 * 7), out_features = 1024)\n",
        "\n",
        "    # Layer 13 --> Fully Connected Layer 2\n",
        "    self.fully_connected2 = Linear(in_features = 1024, out_features = 512)\n",
        "\n",
        "    # Layer 14 --> Fully Connected Layer 3\n",
        "    self.fully_connected3 = Linear(in_features = 512, out_features = 9)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    c1 = Swish(self.conv1(x))\n",
        "    c2 = Swish(self.conv2(c1))\n",
        "    c3 = Swish(self.conv3(c2))\n",
        "    c4 = Swish(self.conv4(c3))\n",
        "    c5 = Swish(self.conv5(c4))\n",
        "    c6 = Swish(self.conv6(c5))\n",
        "    c7 = Swish(self.conv7(c6))\n",
        "    c8 = Swish(self.conv8(c7))\n",
        "    c9 = Swish(self.conv9(c8))\n",
        "\n",
        "    out = self.average_pooling(c9)\n",
        "\n",
        "    out = self.flatten(out)\n",
        "\n",
        "    #if self.fully_connected1 is None:\n",
        "     # input_features = out.size(1) # out5 --> [batch_size, channels, height, width] biz de channels sayisini aldik\n",
        "     # self.fully_connected1 = Linear(in_features = input_features, out_features = 2048)\n",
        "     # self.fully_connected2 = Linear(in_features = 2048, out_features = 1024)\n",
        "     # self.fully_connected3 = Linear(in_features = 1024, out_features = 9)\n",
        "\n",
        "    out = self.fully_connected1(out)\n",
        "    out = self.fully_connected2(out)\n",
        "    out = self.fully_connected3(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = CNN() # model olusturuldu"
      ],
      "metadata": {
        "id": "FnTTBFFDQDP8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train_images = glob.glob(\"/content/train/**/*.jpg\", recursive = True)\n",
        "path_validation_images = glob.glob(\"/content/val/**/*.jpg\", recursive = True)\n",
        "path_test_images = glob.glob(\"/content/test/**/*.jpg\", recursive = True)"
      ],
      "metadata": {
        "id": "SPf2bx-w9Apa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD AND NORMALIZE DATA"
      ],
      "metadata": {
        "id": "lq-6d4W-oXTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Custom_Dataset(image_paths, transform = None):\n",
        "  label_encoder = LabelEncoder()\n",
        "\n",
        "  labels = []\n",
        "  images = []\n",
        "\n",
        "  for i, image_path in enumerate(image_paths):\n",
        "    image = cv2.imread(image_path)\n",
        "    label = image_paths[i].split('/')[-2]  # split hatasını düzelttim\n",
        "\n",
        "\n",
        "    if transform:\n",
        "      image = transform(Image.fromarray(image))  #\n",
        "\n",
        "    images.append(torch.as_tensor(image, dtype=torch.float32).clone().detach())\n",
        "    labels.append(label)\n",
        "\n",
        "  encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "  return TensorDataset(torch.stack(images), torch.tensor(encoded_labels, dtype=torch.long))"
      ],
      "metadata": {
        "id": "AVqTdH7iCqP6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "train_dataset = Custom_Dataset(image_paths = path_train_images, transform = transform)\n",
        "validation_dataset = Custom_Dataset(image_paths = path_validation_images, transform = transform)\n",
        "test_dataset = Custom_Dataset(image_paths = path_test_images, transform = transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 16, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size = 16, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 16, shuffle = True)"
      ],
      "metadata": {
        "id": "s99LTjKIobi9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numpy(tensor):\n",
        "    with torch.no_grad():\n",
        "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy().astype(np.float32)\n",
        "\n",
        "def validation_loop(validation_dataloader, model, loss_fn):\n",
        "    model.eval()  # Modeli değerlendirme moduna geçir\n",
        "\n",
        "    size = len(validation_dataloader.dataset)\n",
        "    num_batches = len(validation_dataloader)\n",
        "    total_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for validation_data, validation_labels in validation_dataloader:\n",
        "            pred = model(validation_data)\n",
        "            total_loss += loss_fn(pred, validation_labels).item()\n",
        "            correct += ((to_numpy(pred.argmax(1)).detach()) == to_numpy(validation_labels.detach())).astype(np.float).sum()\n",
        "\n",
        "    total_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    print(\"Validation Error:\\n\", \"Accuracy:\", round((100 * correct), 4), \" | Average Loss:\", round(total_loss, 4), \"\\n\")"
      ],
      "metadata": {
        "id": "LiQSPJLjaTae"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import detect_anomaly\n",
        "def train_loop(dataloader, model, loss_function, optimizer, validation_dataloader, scheduler, accumulation_steps):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    total_loss, correct = 0, 0\n",
        "    toplam_kayip = 0\n",
        "\n",
        "    for batch, (image, label) in enumerate(dataloader):\n",
        "        pred = model(image)\n",
        "        loss = loss_function(pred, label)\n",
        "\n",
        "        # Gradient biriktirme\n",
        "        loss.backward()\n",
        "        toplam_kayip += loss.item()\n",
        "\n",
        "        if (batch + 1) % accumulation_steps == 0:\n",
        "            # Gradient biriktirme adımında bir güncelleme yap\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Güncelleme sonrasında toplam kaybı yazdır\n",
        "            current = (batch + 1) * len(image)\n",
        "            print(\"| Batch:\", current, \"| Total Loss:\", toplam_kayip, \"\\n\")\n",
        "            toplam_kayip = 0\n",
        "\n",
        "    # Gradient biriktirme adımları bittiğinde son güncellemeyi yap\n",
        "    if toplam_kayip > 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Validation için modeli değerlendir\n",
        "    validation_loop(validation_dataloader, model, loss_function)\n",
        "    model.train()  # Eğitim moduna geri geç\n",
        "\n",
        "    # Öğrenme oranını güncelle\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "v4PvconRCqF0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "\n",
        "    model.eval() # Test yaptigimiz icin eval moddayiz\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader) # toplam batch sayisi\n",
        "    total_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad(): # gradyan hesaplaması yapmamak icin. degerlendirmede parametreleri guncellemeyiz\n",
        "        for image, label in dataloader:\n",
        "            pred = model(image) # tahmin\n",
        "            total_loss += loss_fn(pred, label).item() # toplam kayip\n",
        "            correct += ((to_numpy(pred.argmax(1))).detach() == to_numpy(label.detach())).astype(np.float).sum()  # dogru tahmin\n",
        "\n",
        "    # ortalama kayip ve dogruluk orani\n",
        "    total_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    print(\"Test Error:\\n\", \"Accuracy:\", round((100 * correct),4),\" | Average Loss:\",round(total_loss,4), \"\\n\")"
      ],
      "metadata": {
        "id": "XImc9qC-CqD6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_epochs = 60\n",
        "learning_rate = 1e-3\n",
        "batch_size = 4\n",
        "accumulation_steps = 4  # Her biriktirme adımında bir güncelleme yapılacak\n",
        "# optimizer --> Adam\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss() #siniflandirma icin kul. yaygin loss func.\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)  # Adam optimizer\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40], gamma=0.3)  # belirli araliklarla lr degistirmek icin\n",
        "\n",
        "epochs = number_of_epochs\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch \\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_function, optimizer, validation_dataloader, scheduler,accumulation_steps)\n",
        "    #test_loop(test_dataloader, model, loss_function)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "hTgqr_6OCqBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3e2b6d-1ce0-41f4-cb01-64069b7e813a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch \n",
            "-------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LaZJXs6VzUN9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}