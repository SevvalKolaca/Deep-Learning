{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/test.zip\n",
        "!unzip /content/train.zip"
      ],
      "metadata": {
        "id": "raAZGk6D-9sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6d0612-414b-4463-cdc2-5def4514a65e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip\n",
            "   creating: test/\n",
            "   creating: test/flamingo/\n",
            "  inflating: test/flamingo/image_0022.jpg  \n",
            "  inflating: test/flamingo/image_0024.jpg  \n",
            "  inflating: test/flamingo/image_0041.jpg  \n",
            "  inflating: test/flamingo/image_0043.jpg  \n",
            "  inflating: test/flamingo/image_0047.jpg  \n",
            "  inflating: test/flamingo/image_0050.jpg  \n",
            "  inflating: test/flamingo/image_0051.jpg  \n",
            "  inflating: test/flamingo/image_0059.jpg  \n",
            "   creating: test/pizza/\n",
            "  inflating: test/pizza/image_0024.jpg  \n",
            "  inflating: test/pizza/image_0035.jpg  \n",
            "  inflating: test/pizza/image_0037.jpg  \n",
            "  inflating: test/pizza/image_0038.jpg  \n",
            "  inflating: test/pizza/image_0040.jpg  \n",
            "  inflating: test/pizza/image_0046.jpg  \n",
            "Archive:  /content/train.zip\n",
            "   creating: train/\n",
            "   creating: train/flamingo/\n",
            "  inflating: train/flamingo/image_0001.jpg  \n",
            "  inflating: train/flamingo/image_0002.jpg  \n",
            "  inflating: train/flamingo/image_0003.jpg  \n",
            "  inflating: train/flamingo/image_0004.jpg  \n",
            "  inflating: train/flamingo/image_0005.jpg  \n",
            "  inflating: train/flamingo/image_0006.jpg  \n",
            "  inflating: train/flamingo/image_0007.jpg  \n",
            "  inflating: train/flamingo/image_0008.jpg  \n",
            "  inflating: train/flamingo/image_0009.jpg  \n",
            "  inflating: train/flamingo/image_0010.jpg  \n",
            "  inflating: train/flamingo/image_0011.jpg  \n",
            "  inflating: train/flamingo/image_0012.jpg  \n",
            "  inflating: train/flamingo/image_0013.jpg  \n",
            "  inflating: train/flamingo/image_0015.jpg  \n",
            "  inflating: train/flamingo/image_0016.jpg  \n",
            "  inflating: train/flamingo/image_0017.jpg  \n",
            "  inflating: train/flamingo/image_0018.jpg  \n",
            "  inflating: train/flamingo/image_0019.jpg  \n",
            "  inflating: train/flamingo/image_0021.jpg  \n",
            "  inflating: train/flamingo/image_0023.jpg  \n",
            "  inflating: train/flamingo/image_0025.jpg  \n",
            "  inflating: train/flamingo/image_0027.jpg  \n",
            "  inflating: train/flamingo/image_0028.jpg  \n",
            "  inflating: train/flamingo/image_0029.jpg  \n",
            "  inflating: train/flamingo/image_0030.jpg  \n",
            "  inflating: train/flamingo/image_0031.jpg  \n",
            "  inflating: train/flamingo/image_0032.jpg  \n",
            "  inflating: train/flamingo/image_0033.jpg  \n",
            "  inflating: train/flamingo/image_0034.jpg  \n",
            "  inflating: train/flamingo/image_0035.jpg  \n",
            "  inflating: train/flamingo/image_0036.jpg  \n",
            "  inflating: train/flamingo/image_0037.jpg  \n",
            "  inflating: train/flamingo/image_0038.jpg  \n",
            "  inflating: train/flamingo/image_0039.jpg  \n",
            "  inflating: train/flamingo/image_0040.jpg  \n",
            "  inflating: train/flamingo/image_0042.jpg  \n",
            "  inflating: train/flamingo/image_0044.jpg  \n",
            "  inflating: train/flamingo/image_0046.jpg  \n",
            "  inflating: train/flamingo/image_0048.jpg  \n",
            "  inflating: train/flamingo/image_0052.jpg  \n",
            "  inflating: train/flamingo/image_0053.jpg  \n",
            "  inflating: train/flamingo/image_0054.jpg  \n",
            "  inflating: train/flamingo/image_0055.jpg  \n",
            "  inflating: train/flamingo/image_0056.jpg  \n",
            "  inflating: train/flamingo/image_0057.jpg  \n",
            "  inflating: train/flamingo/image_0058.jpg  \n",
            "  inflating: train/flamingo/image_0060.jpg  \n",
            "  inflating: train/flamingo/image_0061.jpg  \n",
            "  inflating: train/flamingo/image_0062.jpg  \n",
            "  inflating: train/flamingo/image_0063.jpg  \n",
            "  inflating: train/flamingo/image_0064.jpg  \n",
            "  inflating: train/flamingo/image_0066.jpg  \n",
            "  inflating: train/flamingo/image_0067.jpg  \n",
            "   creating: train/pizza/\n",
            "  inflating: train/pizza/image_0001.jpg  \n",
            "  inflating: train/pizza/image_0002.jpg  \n",
            "  inflating: train/pizza/image_0003.jpg  \n",
            "  inflating: train/pizza/image_0004.jpg  \n",
            "  inflating: train/pizza/image_0005.jpg  \n",
            "  inflating: train/pizza/image_0006.jpg  \n",
            "  inflating: train/pizza/image_0007.jpg  \n",
            "  inflating: train/pizza/image_0008.jpg  \n",
            "  inflating: train/pizza/image_0009.jpg  \n",
            "  inflating: train/pizza/image_0010.jpg  \n",
            "  inflating: train/pizza/image_0012.jpg  \n",
            "  inflating: train/pizza/image_0013.jpg  \n",
            "  inflating: train/pizza/image_0014.jpg  \n",
            "  inflating: train/pizza/image_0015.jpg  \n",
            "  inflating: train/pizza/image_0016.jpg  \n",
            "  inflating: train/pizza/image_0017.jpg  \n",
            "  inflating: train/pizza/image_0018.jpg  \n",
            "  inflating: train/pizza/image_0019.jpg  \n",
            "  inflating: train/pizza/image_0020.jpg  \n",
            "  inflating: train/pizza/image_0021.jpg  \n",
            "  inflating: train/pizza/image_0023.jpg  \n",
            "  inflating: train/pizza/image_0026.jpg  \n",
            "  inflating: train/pizza/image_0027.jpg  \n",
            "  inflating: train/pizza/image_0028.jpg  \n",
            "  inflating: train/pizza/image_0029.jpg  \n",
            "  inflating: train/pizza/image_0030.jpg  \n",
            "  inflating: train/pizza/image_0031.jpg  \n",
            "  inflating: train/pizza/image_0032.jpg  \n",
            "  inflating: train/pizza/image_0033.jpg  \n",
            "  inflating: train/pizza/image_0034.jpg  \n",
            "  inflating: train/pizza/image_0036.jpg  \n",
            "  inflating: train/pizza/image_0039.jpg  \n",
            "  inflating: train/pizza/image_0042.jpg  \n",
            "  inflating: train/pizza/image_0043.jpg  \n",
            "  inflating: train/pizza/image_0044.jpg  \n",
            "  inflating: train/pizza/image_0045.jpg  \n",
            "  inflating: train/pizza/image_0048.jpg  \n",
            "  inflating: train/pizza/image_0049.jpg  \n",
            "  inflating: train/pizza/image_0050.jpg  \n",
            "  inflating: train/pizza/image_0051.jpg  \n",
            "  inflating: train/pizza/image_0052.jpg  \n",
            "  inflating: train/pizza/image_0053.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- *LIBRARIES* ----------------------------------------------------------------"
      ],
      "metadata": {
        "id": "kzgRoHElnFQY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uSgXdcfA-nIx"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import glob\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TRAIN IMAGE IMPORT*---------------------------------------------------------"
      ],
      "metadata": {
        "id": "ZTy77N_YnSAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_vectors = []\n",
        "t = []\n",
        "\n",
        "path_train_files = glob.glob(\"/content/train/**/*.jpg\", recursive = True)\n",
        "train_files = []\n",
        "\n",
        "i = 0\n",
        "for file in path_train_files:\n",
        "    train_files.append(file)\n",
        "    train_image = cv2.imread(file)\n",
        "    label = train_files[i].split('/')[-2]\n",
        "\n",
        "    #cv2_imshow(train_image)\n",
        "    #print(train_image.shape)\n",
        "    train_image = cv2.resize(train_image, (128,128))\n",
        "    #cv2_imshow(train_image)\n",
        "    #print(train_image.shape)\n",
        "    flat_train_image = train_image.flatten().astype(np.float16).reshape((1,-1))\n",
        "    train_image_vectors.append(flat_train_image)\n",
        "    t.append(label)\n",
        "    i+=1\n",
        "\n",
        "\n",
        "train_files = np.array(train_files).reshape((1,-1))\n",
        "train_image_vectors = np.array(train_image_vectors)\n",
        "\n",
        "print(t)\n",
        "print(train_files.shape)\n",
        "print(flat_train_image.shape)\n",
        "print(train_image_vectors.shape)\n",
        "# print(train_image_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D6oo237-ruv",
        "outputId": "45468266-cc4e-4882-ea34-325004734412"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza']\n",
            "(1, 95)\n",
            "(1, 49152)\n",
            "(95, 1, 49152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TEST IMAGE IMPORT*----------------------------------------------------------"
      ],
      "metadata": {
        "id": "58DKRNLWnaH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_vectors = []\n",
        "labels_test = []\n",
        "\n",
        "path_test_files = glob.glob(\"/content/test/**/*.jpg\", recursive = True)\n",
        "test_files = []\n",
        "\n",
        "i = 0\n",
        "for file in path_test_files:\n",
        "    test_files.append(file)\n",
        "    test_image = cv2.imread(file)\n",
        "    label = test_files[i].split('/')[-2]\n",
        "\n",
        "    #cv2_imshow(train_image)\n",
        "    #print(train_image.shape)\n",
        "    test_image = cv2.resize(test_image, (128,128))\n",
        "    #cv2_imshow(train_image)\n",
        "    #print(train_image.shape)\n",
        "    flat_test_image = test_image.flatten().astype(np.float16).reshape((1,-1))\n",
        "    test_image_vectors.append(flat_test_image)\n",
        "    labels_test.append(label)\n",
        "    i+=1\n",
        "\n",
        "test_files = np.array(test_files).reshape((1,-1))\n",
        "test_image_vectors = np.array(test_image_vectors)\n",
        "\n",
        "print(labels_test)\n",
        "print(test_files.shape)\n",
        "print(flat_test_image.shape)\n",
        "print(test_image_vectors.shape)\n",
        "\n",
        "# print(test_image_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSLm7x3I-rrm",
        "outputId": "d4d975ed-7ccd-4362-da54-702156deba70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'flamingo', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza', 'pizza']\n",
            "(1, 14)\n",
            "(1, 49152)\n",
            "(14, 1, 49152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*SHUFFLE DATA*--------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "bARWRJLUr936"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_data = list(zip(train_image_vectors, t))\n",
        "combined_test_data = list(zip(test_image_vectors, labels_test))\n",
        "\n",
        "np.random.shuffle(combined_train_data)\n",
        "np.random.shuffle(combined_test_data)\n",
        "\n",
        "train_data, train_labels = zip(*combined_train_data)\n",
        "test_data, test_labels = zip(*combined_test_data)\n",
        "\n",
        "train_data = np.array(train_data)[:,0,:]\n",
        "test_data = np.array(test_data)[:,0,:]\n",
        "\n",
        "train_labels = list(train_labels)\n",
        "test_labels = list(test_labels)"
      ],
      "metadata": {
        "id": "SbwL_Wbn-roE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.dtype)\n",
        "print(test_data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygpqP8Qxrf1u",
        "outputId": "00fb4fa0-17a4-46e3-e761-d49161d74eff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float16\n",
            "float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*LABEL ENCODER*---------------------------------------------"
      ],
      "metadata": {
        "id": "vP2TVgLu3GAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "print(train_labels)\n",
        "# pizza --> 1\n",
        "# flamingo --> 0\n",
        "print(train_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs1aMlwQpSXM",
        "outputId": "c41a3c9a-2915-414b-a5fb-1876ecefc1d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0\n",
            " 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1]\n",
            "(95, 49152)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*CREATE .NPY FILE*-----------------------------------------"
      ],
      "metadata": {
        "id": "1p8cKupxnbJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = \"/content/weights.npy\"\n",
        "if not os.path.exists(weights_path):\n",
        "  os.mknod(weights_path)"
      ],
      "metadata": {
        "id": "s1jV3drvna04"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*AKTIVASYON FONKS*----------------------------------"
      ],
      "metadata": {
        "id": "JvlZNZnlwJQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    x_min = np.min(x)\n",
        "    x_max = np.max(x)\n",
        "    x_normalized = (x - x_min) / (x_max - x_min)\n",
        "    return x_normalized\n",
        "\n",
        "def mish_normalized(x):\n",
        "    x_normalized = normalize(x)\n",
        "    result = x_normalized * tanh(softplus(x_normalized))\n",
        "    return result\n",
        "\n",
        "def tanh(x):\n",
        "    exp_pos = np.exp(x)\n",
        "    exp_neg = np.exp(-x)\n",
        "    denominator = exp_pos + exp_neg\n",
        "    denominator = np.clip(denominator, 1e-15, None)  # Küçük değerleri sınırla\n",
        "    return (exp_pos - exp_neg) / denominator\n",
        "\n",
        "def softplus(x):\n",
        "    return np.log(1 + np.exp(-np.abs(x))) + np.maximum(x, 0)\n",
        "\n",
        "def mish(x):\n",
        "    result = x * tanh(softplus(x))\n",
        "    if np.isnan(result).any():\n",
        "        # NaN değeri tespit edildi,\n",
        "        result = 0  # veya başka bir değer\n",
        "    return result\n",
        "\n",
        "def dmish(x):\n",
        "    omega = np.exp(3*x) + 4*np.exp(2*x) + (6+4*x)*np.exp(x) + 4*(1 + x)\n",
        "    delta = 1 + pow((np.exp(x) + 1), 2)\n",
        "    derivative = np.exp(x) * omega / pow(delta, 2)\n",
        "    if np.isnan(derivative).any():\n",
        "        # NaN değeri tespit edildi,\n",
        "        derivative = 0 # veya başka bir değer\n",
        "    return derivative"
      ],
      "metadata": {
        "id": "sfAGG5swKoHM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TRAIN BIAS EKLEME*----------------------------------"
      ],
      "metadata": {
        "id": "ysLCFC6GwBJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_train = np.ones((train_data.shape[0], 1))    # 1'lerden olusan yeni bir sutun bias icin\n",
        "train_data = np.hstack((train_data, new_column_train))  # hstack ile iki diziyi yatay olarak birlestirir.\n",
        "print(train_data.shape)\n",
        "input_number_train = train_data.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrTHF-7hMmFU",
        "outputId": "3a7ec6c5-3606-4899-f30c-59c42a0eebed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(95, 49153)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TRAIN PERCEPTRON FUNC*-----------------------------\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1pfbNaSZlCN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainPerceptron(inputs, t, weights, rho, iterNo): # trin weights\n",
        "  #threshold = 1.5\n",
        "  #inputs = train_data\n",
        "  #t = train_labels\n",
        "  #bias = 1\n",
        "  for _ in range(iterNo):\n",
        "    for i in range(train_data.shape[0]):\n",
        "      x = inputs[i]\n",
        "      output = np.dot(x,weights) # ic carpim: iki vektoru carp sonuclari topla\n",
        "      y = mish(output)\n",
        "      error = t[i] - y\n",
        "      dW = rho*error*dmish(y)*x\n",
        "      dW = np.array(dW).reshape((-1,1))\n",
        "      #print(dW.shape, weights.shape)\n",
        "\n",
        "      #if np.isnan(dW).any():\n",
        "      # print(\"NaN değeri tespit edildi.\")\n",
        "      weights += dW\n",
        "  np.save('weights.npy', weights) # save weights\n",
        "\n",
        "  return weights"
      ],
      "metadata": {
        "id": "EyYo_kj_rso4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TRAIN WEIGHTS*------------------------------------"
      ],
      "metadata": {
        "id": "ah-yMI-pwRDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate(rho) = 0.0001\n",
        "# iteration number(iterNo) = 1000\n",
        "# initial weight =\n",
        "# initial_weights = 0.1 *(np.random.rand(len(train_data[0]), 1))\n",
        "initial_weights = 0.001 * np.random.randn(len(train_data[0]), 1)\n",
        "print(initial_weights.shape)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_data_normalized = scaler.fit(train_data)\n",
        "train_data_normalized = scaler.transform(train_data)\n",
        "\n",
        "trained_weights = trainPerceptron(train_data, train_labels, initial_weights, 0.0001, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zkh8rxwow-d",
        "outputId": "c374cb9f-21fe-43f4-fdef-46e0405d2eca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49153, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-52f90feb09e8>:13: RuntimeWarning: overflow encountered in exp\n",
            "  exp_pos = np.exp(x)\n",
            "<ipython-input-8-52f90feb09e8>:17: RuntimeWarning: invalid value encountered in divide\n",
            "  return (exp_pos - exp_neg) / denominator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trained_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W-CL-D8TWNv",
        "outputId": "aa50086c-045a-4d61-a2df-9add3e44884c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[315.30075597]\n",
            " [326.33964663]\n",
            " [373.85882303]\n",
            " ...\n",
            " [354.72017495]\n",
            " [410.87839092]\n",
            " [  2.52122558]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TEST BIAS EKLEME*----------------------------------"
      ],
      "metadata": {
        "id": "c7N9wBWUwdqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_test = np.ones((test_data.shape[0], 1))      # 1'lerden olusan yeni bir sutun bias icin\n",
        "test_data = np.hstack((test_data, new_column_test))     # hstack ile iki diziyi yatay olarak birlestirir.\n"
      ],
      "metadata": {
        "id": "q3QuGnVYSJuI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- *TEST PERCEPTRON FUNC*----------------------------"
      ],
      "metadata": {
        "id": "cCV3fKbzlJ54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_normalized = scaler.transform(test_data)\n",
        "\n",
        "def testPerceptron(sample_test, weights):\n",
        "  # sample_test = test_data\n",
        "  # weights = trained_weights\n",
        "  labels = []\n",
        "  for i in range(sample_test.shape[0]):\n",
        "    predict = np.dot(sample_test[i], weights)\n",
        "    print(predict)\n",
        "    predicted_label = mish(predict)\n",
        "    labels.append(predicted_label)\n",
        "  return labels"
      ],
      "metadata": {
        "id": "HW7CJuXM3UWA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data_normalized)\n",
        "print(train_data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBkXvXdhqwEb",
        "outputId": "3d21cd11-8ecc-4d08-aacf-e9834cb80208"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29803922 0.36862745 0.78431373 ... 0.22745098 0.27058824 0.        ]\n",
            " [0.20392157 0.2627451  0.29803922 ... 1.         1.         0.        ]\n",
            " [0.07843137 0.21568627 0.25490196 ... 1.         1.         0.        ]\n",
            " ...\n",
            " [0.87843137 0.94509804 0.98039216 ... 0.57254902 0.83529412 0.        ]\n",
            " [1.         1.         0.99607843 ... 1.         1.         0.        ]\n",
            " [0.34117647 0.54901961 0.74901961 ... 0.49803922 0.61176471 0.        ]]\n",
            "[[0.2        0.19215686 0.18823529 ... 0.81568627 0.85882353 0.        ]\n",
            " [0.16862745 0.20784314 0.19607843 ... 0.54509804 0.61176471 0.        ]\n",
            " [0.99607843 0.99607843 0.99607843 ... 0.99607843 0.99607843 0.        ]\n",
            " ...\n",
            " [0.1372549  0.14509804 0.1254902  ... 0.54509804 0.53333333 0.        ]\n",
            " [0.55686275 0.65098039 0.74509804 ... 0.42352941 0.41568627 0.        ]\n",
            " [0.30196078 0.19607843 0.11764706 ... 0.98431373 0.98431373 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*TEST LABEL ENCODER*-----------------------------"
      ],
      "metadata": {
        "id": "F-Styyk5wkeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = label_encoder.transform(test_labels)"
      ],
      "metadata": {
        "id": "cydSkgZrvqyo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.load('weights.npy') # trainPerceptron ile ogrenilmis weight verileri\n",
        "sample_test = test_data_normalized\n",
        "weights = weights\n",
        "\n",
        "print(sample_test.shape)\n",
        "print(weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhx6RwpLgqhu",
        "outputId": "7b0c64b8-d7f5-4d53-bfe6-a64ac812f032"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14, 49153)\n",
            "(49153, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*PREDICT*-------------------------------------"
      ],
      "metadata": {
        "id": "PKpEDqAWwtDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = testPerceptron(sample_test, weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCdSToqDmXG-",
        "outputId": "4549fc76-5953-4e45-fcf9-8555c996d8cb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6987130.511808]\n",
            "[6580094.92834617]\n",
            "[8038248.55839092]\n",
            "[6526252.57474862]\n",
            "[7863392.46611234]\n",
            "[6206785.18395277]\n",
            "[12262886.74381001]\n",
            "[9831174.1436014]\n",
            "[10505981.13473127]\n",
            "[11250932.67148585]\n",
            "[9541711.47762218]\n",
            "[9499123.88820155]\n",
            "[11391339.13576499]\n",
            "[7577892.45414148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-a0c66f529d81>:13: RuntimeWarning: overflow encountered in exp\n",
            "  exp_pos = np.exp(x)\n",
            "<ipython-input-30-a0c66f529d81>:17: RuntimeWarning: invalid value encountered in divide\n",
            "  return (exp_pos - exp_neg) / denominator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*PREADICT AND TEST LABELS*-------------------------------"
      ],
      "metadata": {
        "id": "rcJnG6c2w7mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = np.array(predicts)\n",
        "print(\"Predicted Labels: \", predicts)\n",
        "\n",
        "print(\"Test Labels: \",test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n85ML7brxaAH",
        "outputId": "750bdd85-bc69-4279-ad02-06dc84716e53"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Test Labels:  [0 0 0 0 1 0 1 1 1 0 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---*ACCURACY SCORE*------------------------------------------"
      ],
      "metadata": {
        "id": "ccMAWjxBxADY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(test_labels,predicts)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "whCMv-SesGBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9f5499-8932-493d-ecad-d7d7d4ba6b5e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.42857142857142855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARTCJfYmxSMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}